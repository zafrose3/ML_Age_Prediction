{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzkhYP4yu3SY"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"NHANES_age_prediction.csv\")\n",
        "\n",
        "# Clean column names to avoid whitespace issues\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Encode target\n",
        "df['age_group'] = LabelEncoder().fit_transform(df['age_group'])\n",
        "\n",
        "# Drop ID column\n",
        "if 'SEQN' in df.columns:\n",
        "    df.drop('SEQN', axis=1, inplace=True)\n",
        "\n",
        "# Features and Target\n",
        "X = df.drop('age_group', axis=1)\n",
        "y = df['age_group']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define baseline models\n",
        "models = {\n",
        "    \"SVM RBF\": SVC(kernel='rbf'),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1)),\n",
        "    \"Gradient Boost\": GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "baseline_scores = {}\n",
        "for name, model in models.items():\n",
        "    score = cross_val_score(model, X_train, y_train, cv=5).mean()\n",
        "    baseline_scores[name] = score\n",
        "    print(f\"Baseline {name}: {score:.4f}\")\n"
      ],
      "metadata": {
        "id": "64y3gU1Gvvtn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "3ee14c84-4aba-4266-e2cd-24c30259f568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3b07e94cf1d6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"SVM RBF\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"Random Forest\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;34m\"AdaBoost\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"Gradient Boost\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m }\n",
            "\u001b[0;31mTypeError\u001b[0m: AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomized Search\n",
        "svm = SVC(kernel='rbf')\n",
        "svm_random_grid = {'C': np.logspace(-2, 3, 20), 'gamma': np.logspace(-4, 1, 20)}\n",
        "svm_random = RandomizedSearchCV(svm, svm_random_grid, cv=5, n_iter=20, random_state=42)\n",
        "svm_random.fit(X_train, y_train)\n",
        "\n",
        "# Grid Search on narrowed range\n",
        "C_vals = np.linspace(svm_random.best_params_['C']*0.5, svm_random.best_params_['C']*1.5, 5)\n",
        "gamma_vals = np.linspace(svm_random.best_params_['gamma']*0.5, svm_random.best_params_['gamma']*1.5, 5)\n",
        "svm_grid = {'C': C_vals, 'gamma': gamma_vals}\n",
        "svm_grid_search = GridSearchCV(svm, svm_grid, cv=5)\n",
        "svm_grid_search.fit(X_train, y_train)\n",
        "\n",
        "svm_best_score = svm_grid_search.best_score_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5oM5cRKZKlUg",
        "outputId": "ff3438cf-b036-4f7d-881b-5171eb761740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_scaled' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-009b476928ba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparam_dist_svr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gamma'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrand_search_svr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dist_svr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrand_search_svr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbest_params_svr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_search_svr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf_random_grid = {'n_estimators': np.arange(10, 200, 10), 'max_depth': np.arange(2, 20)}\n",
        "rf_random = RandomizedSearchCV(rf, rf_random_grid, cv=5, n_iter=20, random_state=42)\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "# Grid Search\n",
        "n_est = [rf_random.best_params_['n_estimators'] - 10, rf_random.best_params_['n_estimators'], rf_random.best_params_['n_estimators'] + 10]\n",
        "depths = [rf_random.best_params_['max_depth'] - 2, rf_random.best_params_['max_depth'], rf_random.best_params_['max_depth'] + 2]\n",
        "rf_grid = {'n_estimators': n_est, 'max_depth': depths}\n",
        "rf_grid_search = GridSearchCV(rf, rf_grid, cv=5)\n",
        "rf_grid_search.fit(X_train, y_train)\n",
        "\n",
        "rf_best_score = rf_grid_search.best_score_\n"
      ],
      "metadata": {
        "id": "YZHHJRUB_PZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adb = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1))\n",
        "adb_random_grid = {'n_estimators': np.arange(10, 200, 10), 'learning_rate': np.linspace(0.01, 1.0, 20)}\n",
        "adb_random = RandomizedSearchCV(adb, adb_random_grid, cv=5, n_iter=20, random_state=42)\n",
        "adb_random.fit(X_train, y_train)\n",
        "\n",
        "n_est = [adb_random.best_params_['n_estimators'] - 10, adb_random.best_params_['n_estimators'], adb_random.best_params_['n_estimators'] + 10]\n",
        "lr = np.linspace(adb_random.best_params_['learning_rate']*0.8, adb_random.best_params_['learning_rate']*1.2, 5)\n",
        "adb_grid = {'n_estimators': n_est, 'learning_rate': lr}\n",
        "adb_grid_search = GridSearchCV(adb, adb_grid, cv=5)\n",
        "adb_grid_search.fit(X_train, y_train)\n",
        "\n",
        "adb_best_score = adb_grid_search.best_score_\n"
      ],
      "metadata": {
        "id": "OMBy22Lx_QPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingClassifier()\n",
        "gb_random_grid = {'n_estimators': np.arange(50, 200, 10), 'max_depth': np.arange(2, 10)}\n",
        "gb_random = RandomizedSearchCV(gb, gb_random_grid, cv=5, n_iter=20, random_state=42)\n",
        "gb_random.fit(X_train, y_train)\n",
        "\n",
        "n_est = [gb_random.best_params_['n_estimators'] - 10, gb_random.best_params_['n_estimators'], gb_random.best_params_['n_estimators'] + 10]\n",
        "depths = [gb_random.best_params_['max_depth'] - 1, gb_random.best_params_['max_depth'], gb_random.best_params_['max_depth'] + 1]\n",
        "gb_grid = {'n_estimators': n_est, 'max_depth': depths}\n",
        "gb_grid_search = GridSearchCV(gb, gb_grid, cv=5)\n",
        "gb_grid_search.fit(X_train, y_train)\n",
        "\n",
        "gb_best_score = gb_grid_search.best_score_\n"
      ],
      "metadata": {
        "id": "H2uXsTY4_Snx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_scores = {\n",
        "    \"SVM RBF\": svm_best_score,\n",
        "    \"Random Forest\": rf_best_score,\n",
        "    \"AdaBoost\": adb_best_score,\n",
        "    \"Gradient Boost\": gb_best_score\n",
        "}\n",
        "\n",
        "# Combine results\n",
        "labels = list(baseline_scores.keys())\n",
        "baseline_vals = [baseline_scores[k] for k in labels]\n",
        "tuned_vals = [tuned_scores[k] for k in labels]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars1 = plt.bar(x - width/2, baseline_vals, width, label='Baseline')\n",
        "bars2 = plt.bar(x + width/2, tuned_vals, width, label='Tuned')\n",
        "\n",
        "plt.ylabel('Cross-Validation Accuracy')\n",
        "plt.title('Model Performance (Baseline vs Tuned)')\n",
        "plt.xticks(x, labels)\n",
        "plt.legend()\n",
        "\n",
        "# Add value labels\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f'{yval:.2f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-wg_1QsM_VCx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}